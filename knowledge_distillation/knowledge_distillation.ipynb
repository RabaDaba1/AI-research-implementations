{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "778376ef",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69359ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f13a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd2333",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0219993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.5071, 0.4867, 0.4408]\n",
    "std = [0.2675, 0.2565, 0.2761]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                             download=True, transform=train_transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                            download=True, transform=test_transform)\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Testing dataset size: {len(test_dataset)}\")\n",
    "print(f\"Number of classes: {len(train_dataset.classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662b52e0",
   "metadata": {},
   "source": [
    "# Models (Teacher and Student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e6e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_teacher_model():\n",
    "    model = models.resnet50(weights=None)\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 100)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_student_model():\n",
    "    model = models.resnet18(weights=None)\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 100)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8aa974",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = create_teacher_model().to(device)\n",
    "student_model = create_student_model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3437a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Teacher model (ResNet-50) parameters: {count_parameters(teacher_model):,}\")\n",
    "print(f\"Student model (ResNet-18) parameters: {count_parameters(student_model):,}\")\n",
    "print(f\"Compression ratio: {count_parameters(teacher_model) / count_parameters(student_model):.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfc2560",
   "metadata": {},
   "source": [
    "# Training the Teacher Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7f7a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, epochs, save_path=None):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_loss': [],\n",
    "        'test_acc': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
    "        for inputs, targets in progress_bar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += targets.size(0)\n",
    "            train_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar.set_postfix(\n",
    "                {\"loss\": loss.item(), \"acc\": 100 * train_correct / train_total}\n",
    "            )\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = 100.0 * train_correct / train_total\n",
    "        \n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{epochs} [Valid]\"):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                test_total += targets.size(0)\n",
    "                test_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                progress_bar.set_postfix(\n",
    "                    {\"loss\": loss.item(), \"acc\": 100 * test_correct / test_total}\n",
    "                )\n",
    "        \n",
    "        test_loss = test_loss / len(test_loader.dataset)\n",
    "        test_acc = 100.0 * test_correct / test_total\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        if test_acc > best_acc and save_path:\n",
    "            best_acc = test_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Saved best model with accuracy: {best_acc:.2f}%\")\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "              f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc94f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_path = './teacher_model.pth'\n",
    "if os.path.exists(teacher_path):\n",
    "    print(\"Loading pre-trained teacher model...\")\n",
    "    teacher_model.load_state_dict(torch.load(teacher_path))\n",
    "else:\n",
    "    print(\"Training teacher model...\")\n",
    "    teacher_model, teacher_history = train_model(\n",
    "        teacher_model, train_loader, test_loader, epochs=100, save_path=teacher_path, is_teacher=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1d51e2",
   "metadata": {},
   "source": [
    "# Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7a4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, temperature=4.0):\n",
    "        super(DistillationLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, student_outputs, teacher_outputs, targets):\n",
    "        hard_loss = self.criterion(student_outputs, targets)\n",
    "        soft_student = F.log_softmax(student_outputs / self.temperature, dim=1)\n",
    "        soft_teacher = F.softmax(teacher_outputs / self.temperature, dim=1)\n",
    "        soft_loss = F.kl_div(soft_student, soft_teacher, reduction='batchmean') * (self.temperature ** 2)\n",
    "        return (1 - self.alpha) * hard_loss + self.alpha * soft_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99969b2a",
   "metadata": {},
   "source": [
    "# Training Students (From Scratch vs Distillation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15a6c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model_baseline = create_student_model().to(device)\n",
    "\n",
    "print(\"Training student model from scratch without distillation...\")\n",
    "student_baseline_path = './student_baseline_model.pth'\n",
    "student_model_baseline, student_baseline_history = train_model(\n",
    "    student_model_baseline, train_loader, test_loader, epochs=100,\n",
    "    save_path=student_baseline_path, is_teacher=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b1fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_student_with_distillation(student_model, teacher_model, train_loader, test_loader, epochs, alpha=0.5, temperature=4.0, save_path=None):\n",
    "    distillation_criterion = DistillationLoss(alpha=alpha, temperature=temperature)\n",
    "    standard_criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = optim.AdamW(student_model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_loss': [],\n",
    "        'test_acc': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        student_model.train()\n",
    "        teacher_model.eval()\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():\n",
    "                student_outputs = student_model(inputs)\n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs = teacher_model(inputs)\n",
    "                \n",
    "                loss = distillation_criterion(student_outputs, teacher_outputs, targets)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = student_outputs.max(1)\n",
    "            train_total += targets.size(0)\n",
    "            train_correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = 100.0 * train_correct / train_total\n",
    "\n",
    "        student_model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{epochs} - Testing\"):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                \n",
    "                outputs = student_model(inputs)\n",
    "                loss = standard_criterion(outputs, targets)\n",
    "                \n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                test_total += targets.size(0)\n",
    "                test_correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        test_loss = test_loss / len(test_loader.dataset)\n",
    "        test_acc = 100.0 * test_correct / test_total\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        if test_acc > best_acc and save_path:\n",
    "            best_acc = test_acc\n",
    "            torch.save(student_model.state_dict(), save_path)\n",
    "            print(f\"Saved best model with accuracy: {best_acc:.2f}%\")\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "              f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "    \n",
    "    return student_model, history\n",
    "\n",
    "print(\"Training student model with knowledge distillation...\")\n",
    "student_distill_path = './student_distill_model.pth'\n",
    "student_model_distill, student_distill_history = train_student_with_distillation(\n",
    "    student_model, teacher_model, train_loader, test_loader, \n",
    "    epochs=100, alpha=0.5, temperature=4.0,\n",
    "    save_path=student_distill_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce12913c",
   "metadata": {},
   "source": [
    "## 7. Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cfe8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, model_name):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    class_correct = list(0. for i in range(100))\n",
    "    class_total = list(0. for i in range(100))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc=f\"Evaluating {model_name}\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            c = (predicted == targets).squeeze()\n",
    "            for i in range(targets.size(0)):\n",
    "                label = targets[i].item()\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "    \n",
    "    overall_acc = 100.0 * correct / total\n",
    "    print(f\"{model_name} - Test Accuracy: {overall_acc:.2f}%\")\n",
    "    \n",
    "    class_accuracies = []\n",
    "    for i in range(100):\n",
    "        if class_total[i] > 0:\n",
    "            class_acc = 100.0 * class_correct[i] / class_total[i]\n",
    "            class_accuracies.append(class_acc)\n",
    "    \n",
    "    avg_class_acc = sum(class_accuracies) / len(class_accuracies)\n",
    "    print(f\"{model_name} - Average Class Accuracy: {avg_class_acc:.2f}%\")\n",
    "    \n",
    "    return overall_acc, avg_class_acc\n",
    "\n",
    "teacher_model.load_state_dict(torch.load(teacher_path))\n",
    "student_model_baseline.load_state_dict(torch.load(student_baseline_path))\n",
    "student_model_distill.load_state_dict(torch.load(student_distill_path))\n",
    "\n",
    "teacher_acc, teacher_class_acc = evaluate_model(teacher_model, test_loader, \"Teacher (ResNet-50)\")\n",
    "baseline_acc, baseline_class_acc = evaluate_model(student_model_baseline, test_loader, \"Student Baseline (ResNet-18)\")\n",
    "distill_acc, distill_class_acc = evaluate_model(student_model_distill, test_loader, \"Student with Distillation (ResNet-18)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a30515",
   "metadata": {},
   "source": [
    "## 8. Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(student_baseline_history['test_acc'], label='Student Baseline')\n",
    "plt.plot(student_distill_history['test_acc'], label='Student with Distillation')\n",
    "plt.axhline(y=teacher_acc, color='r', linestyle='--', label='Teacher')\n",
    "plt.title('Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(student_baseline_history['test_loss'], label='Student Baseline')\n",
    "plt.plot(student_distill_history['test_loss'], label='Student with Distillation')\n",
    "plt.title('Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "models = ['Teacher (ResNet-50)', 'Student Baseline (ResNet-18)', 'Student with Distillation (ResNet-18)']\n",
    "accuracies = [teacher_acc, baseline_acc, distill_acc]\n",
    "model_sizes = [count_parameters(teacher_model), count_parameters(student_model_baseline), count_parameters(student_model_distill)]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(models, accuracies, color=['blue', 'orange', 'green'])\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xticks(rotation=15, ha='right')\n",
    "plt.ylim(0, 100)\n",
    "for i, v in enumerate(accuracies):\n",
    "    plt.text(i, v + 1, f\"{v:.2f}%\", ha='center')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sizes_in_millions = [s / 1000000 for s in model_sizes]\n",
    "plt.bar(models, sizes_in_millions, color=['blue', 'orange', 'green'])\n",
    "plt.title('Model Size Comparison')\n",
    "plt.ylabel('Parameters (millions)')\n",
    "plt.xticks(rotation=15, ha='right')\n",
    "for i, v in enumerate(sizes_in_millions):\n",
    "    plt.text(i, v + 0.1, f\"{v:.2f}M\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a678b06",
   "metadata": {},
   "source": [
    "## 9. Inference Speed Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1e9713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_inference_time(model, input_size=(128, 3, 32, 32), iterations=100):\n",
    "    model.eval()\n",
    "    x = torch.randn(input_size).to(device)\n",
    "    \n",
    "    # Warm-up\n",
    "    with torch.no_grad():\n",
    "        for _ in range(10):\n",
    "            _ = model(x)\n",
    "    \n",
    "    # Measure\n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(iterations):\n",
    "            _ = model(x)\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "    return elapsed_time / iterations * 1000  # Convert to ms per batch\n",
    "\n",
    "teacher_time = measure_inference_time(teacher_model)\n",
    "student_baseline_time = measure_inference_time(student_model_baseline)\n",
    "student_distill_time = measure_inference_time(student_model_distill)\n",
    "\n",
    "print(f\"Teacher (ResNet-50) inference time: {teacher_time:.2f} ms/batch\")\n",
    "print(f\"Student Baseline (ResNet-18) inference time: {student_baseline_time:.2f} ms/batch\")\n",
    "print(f\"Student with Distillation (ResNet-18) inference time: {student_distill_time:.2f} ms/batch\")\n",
    "print(f\"Speed-up: {teacher_time / student_distill_time:.2f}x\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "inference_times = [teacher_time, student_baseline_time, student_distill_time]\n",
    "plt.bar(models, inference_times, color=['blue', 'orange', 'green'])\n",
    "plt.title('Inference Time Comparison')\n",
    "plt.ylabel('Time per batch (ms)')\n",
    "plt.xticks(rotation=15, ha='right')\n",
    "for i, v in enumerate(inference_times):\n",
    "    plt.text(i, v + 0.2, f\"{v:.2f} ms\", ha='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
